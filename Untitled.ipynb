{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Term 1 Project 1 : Finding Lane Lines on the Road** \n",
    "### ** Project Writeup**\n",
    "\n",
    "**Input**   Images or Color Videos<br/>\n",
    "**Output**  Images or Color Vidoes with two solid lines marking the left and right lanes on the road<br/>\n",
    "\n",
    "This writeup contains the code to determine Lanes in Images and Videos\n",
    "This code can be applied to almost any types of road images/videos with decent lane markings\n",
    "\n",
    "At a high level, the code has the following functions\n",
    "\n",
    "**Color Conversion to Hue-Light-Saturation(HLS)**<br/>\n",
    "It turns out that Canny Edge Detection works better if you start off with a HLS space image rather than in RGB Space(a regular color image). That's because the Yellow & White regions are highlighted in a much brighter form in HLS space rather than RGB space<br/>\n",
    "*Images below show an RGB Image vs Image in HLS Space*\n",
    "\n",
    "Original(RGB) Space | HLS Space\n",
    "- | - \n",
    "![Original(RGB) Space](test_images_output/SolidWhiteTransformations/solidWhiteCurve.jpg) | ![HLS Space](test_images_output/SolidWhiteTransformations/output_hls_solidWhiteCurve.jpg)\n",
    "\n",
    "**Color Conversion to Gray Scale**<br/>\n",
    "Conversion to Gray scale helps greatly in computation. That's because a regular color image has 4 channels - R, G, B & Alpha. Whereas Grayscale has only 1 channel. This reduces the computational needs by a lot<br/>\n",
    "*Images below show an RGB Image vs Image in Gray Scale*\n",
    "\n",
    "Original(RGB) Space | Gray Space\n",
    "- | - \n",
    "![Original(RGB) Space](test_images_output/SolidWhiteTransformations/solidWhiteCurve.jpg) | ![Gray Space](test_images_output/SolidWhiteTransformations/output_gray_solidWhiteCurve.jpg)\n",
    "\n",
    "**Applying Gaussian Blur**<br/>\n",
    "Applying Gaussian Blur makes the next process of Canny Detection much better as this removes any sudden spikes and introduces a normalization<br/>\n",
    "*Images below show a Gray Scale Image vs its Gaussian counterpart*\n",
    "\n",
    "Gray Space Image | Gaussian Blurred Image\n",
    "- | - \n",
    "![Gray Space Image](test_images_output/SolidWhiteTransformations/output_gray_solidWhiteCurve.jpg) | ![Gaussian Blurred Image](test_images_output/SolidWhiteTransformations/output_gaussian_solidWhiteCurve.jpg)\n",
    "\n",
    "**Canny Edge Detection**<br/>\n",
    "It turns out that edges are what drives the object(line in this case) detection, and Canny edges is one of the mainstream methodologies to do it. It isolates all the smooth stuff and highlights only the edges so that it is much easier to work<br/>\n",
    "*Images below the Gaussian Smoothed Image and its Canny Transformation outcome*\n",
    "\n",
    "Gaussian Blurred Image | Canny Edges\n",
    "- | - \n",
    "![Gaussian Blurred Image](test_images_output/SolidWhiteTransformations/output_gaussian_solidWhiteCurve.jpg) | ![Canny Edges](test_images_output/SolidWhiteTransformations/output_canny_solidWhiteCurve.jpg)\n",
    "\n",
    "**Region of Interest determination to evaluate only the region of interest**<br/>\n",
    "We really want to consider only the lane before us, and isolate all the other stuff which is not of any importance for this specific problem. Hence we'll create a mask around our region of interest by identifying the vertices and filter the canny output with this mask so that the resulting image has canny edges only in the region of interest<br/>\n",
    "*Images below shows how a Canny output is masked for Region of Interest*\n",
    "\n",
    "Canny Edges | Canny Edges in Region of Interest\n",
    "- | - \n",
    "![Canny Edges](test_images_output/SolidWhiteTransformations/output_canny_solidWhiteCurve.jpg) | ![Canny Edges in Region of Interest](test_images_output/SolidWhiteTransformations/output_roi_solidWhiteCurve.jpg)\n",
    "\n",
    "**Hough Transformation**<br/>\n",
    "Hough transformation transforms every point in the cartesian space to a line in Hough space. This helps to identify the weighted average and determine the best possible lines for our problem<br/>\n",
    "*Images below show an Image with ROI applied and its Hough transformation that results in Hough lines*\n",
    "\n",
    "Canny Edges in Region of Interest | Image with Hough Lines & Extrapolation\n",
    "- | - \n",
    "![Canny Edges in Region of Interest](test_images_output/SolidWhiteTransformations/output_roi_solidWhiteCurve.jpg) | ![Image with Hough Lines](test_images_output/SolidWhiteTransformations/output_hough_solidWhiteCurve.jpg)\n",
    "\n",
    "**Averaging/Extrapolating Lines based on the outputs from Hough Transformation**<br/>\n",
    "For every image, we'll get multiple lines in Hough space. We need to find a way to average these lines and come up with one single line that has the mean slope of all these lines. The length of this line can be arbitrarily set based on our requirement. This is done in the following way\n",
    "\n",
    "Hough Line Transformation returns a series of  lines. We can extract start and end co-ordinates in XY space for each line. We can use these co-ordinates to determine various attributes like mean, slope and intercept.\n",
    "\n",
    "For each line in Hough space, determine the mean X, Y, and slope\n",
    "If Slope is positive ==> it is right inclined meaning left lane. Similar logic for right lane\n",
    "You can ignore the near horizontal lines as you would never have a path horizontal to your vehicle on the road\n",
    "Once the mean X,Y & Slope are available, you can extrapolate the line by using the formula\n",
    "Given a point (x1,y1) and slope m, (y-y1) = m(x-x1) ==> x = ((y-y1)/m) + x1\n",
    "So, determine point x y randomly defining y - since this is an equation, any value of y will correspond to its equivalent x<br/>\n",
    "\n",
    "*Images below show the final Input Image, Hough output, and Input Image with solid lane markers*\n",
    "\n",
    "Original(RGB) Space | Image with Hough Lines & Extrapolation | Image with Lane Markers\n",
    "- | - \n",
    "![Original(RGB) Space](test_images_output/SolidWhiteTransformations/solidWhiteCurve.jpg) | ![Image with Hough Lines](test_images_output/SolidWhiteTransformations/output_hough_solidWhiteCurve.jpg) | ![Image with Lane Markers](test_images_output/SolidWhiteTransformations/output_solidWhiteCurve.jpg)\n",
    "\n",
    "\n",
    "Once all the above methods are defined, the ask is just about using these functions in a proper way to get the resulting output.\n",
    "\n",
    "## Reflection\n",
    "### Lane Finding Pipeline<br/>\n",
    "This code snippet is just using the helper functions defined above in the right order. This returns the weighted image which is a combination of the original image and the two solid lines for the lanes.\n",
    "*Images below show the final Input Image and the Input Image with solid lane markers*\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
